{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "from google_scholar_crawler import SwufeGoogleCrawler\n",
    "\n",
    "# 读取Excel文件\n",
    "paper = pd.read_excel('paper.xlsx')\n",
    "titles = paper['title'].tolist()\n",
    "\n",
    "max_count = len(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 谷歌学术网址\n",
    "gg_search_url = r'https://scholar.google.com.hk/scholar?hl=zh-CN&as_sdt=0%2C5&q='\n",
    "\n",
    "crawler = SwufeGoogleCrawler(gg_search_url)   # 实例化爬虫对象，并导航到谷歌网页\n",
    "\n",
    "cite_website = []\n",
    "count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for title in titles:\n",
    "    cite_website.append(crawler.cited_website_update(title))  # 调用获取引用量方法\n",
    "\n",
    "    # 使用json.dumps将字典转换为字符串\n",
    "    dict_as_string = json.dumps(cite_website[-1])\n",
    "\n",
    "    # 将转换后的字符串写入文件\n",
    "    with open('cite_website_2024.txt', 'a') as file:  # 'a' 表示追加模式\n",
    "        file.write(dict_as_string + '\\n')  # 写入最新的数据并换行\n",
    "\n",
    "    print(f'已完成 {count} 篇引用量更新')\n",
    "    print(f'剩余 {max_count - count} 篇')\n",
    "    count += 1\n",
    "    time.sleep(2)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
